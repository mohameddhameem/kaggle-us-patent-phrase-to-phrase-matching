{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n#ref - https://www.kaggle.com/code/mohamadmerchant/us-phrase-matching-tf-keras-train-tpu\n# Additional - https://www.kaggle.com/code/znu808/uspppm-bertforpatent-keras-prediction","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-13T12:16:27.225443Z","iopub.execute_input":"2022-05-13T12:16:27.225909Z","iopub.status.idle":"2022-05-13T12:16:27.269411Z","shell.execute_reply.started":"2022-05-13T12:16:27.225782Z","shell.execute_reply":"2022-05-13T12:16:27.268222Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nfrom scipy import stats\nfrom sklearn.model_selection import StratifiedKFold\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nimport tensorflow_addons as tfa\n\nimport transformers\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") \n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:16:29.504841Z","iopub.execute_input":"2022-05-13T12:16:29.505553Z","iopub.status.idle":"2022-05-13T12:16:41.623939Z","shell.execute_reply.started":"2022-05-13T12:16:29.505506Z","shell.execute_reply":"2022-05-13T12:16:41.622112Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:16:41.626644Z","iopub.execute_input":"2022-05-13T12:16:41.627017Z","iopub.status.idle":"2022-05-13T12:16:41.637069Z","shell.execute_reply.started":"2022-05-13T12:16:41.626971Z","shell.execute_reply":"2022-05-13T12:16:41.636488Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"if tf.test.gpu_device_name():\n    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\nelse:\n    print(\"we are running on CPU. switch to GPU for full training\")","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:16:41.638150Z","iopub.execute_input":"2022-05-13T12:16:41.638442Z","iopub.status.idle":"2022-05-13T12:16:41.677492Z","shell.execute_reply.started":"2022-05-13T12:16:41.638416Z","shell.execute_reply":"2022-05-13T12:16:41.676679Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_codes = pd.read_csv('../input/cpc-codes/titles.csv')\ndata = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/train.csv', ) #nrows=1000\ntest_data = pd.read_csv('../input/us-patent-phrase-to-phrase-matching/test.csv')\nprint(data.shape, test_data.shape)\ncodes = df_codes.rename(columns = {\"code\" : \"context\"})\ntrain_data=pd.merge(data,codes[[\"context\",\"title\"]],on=\"context\",how=\"left\")\ntest_data=pd.merge(test_data,codes[[\"context\",\"title\"]],on=\"context\",how=\"left\")\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:20:13.530573Z","iopub.execute_input":"2022-05-13T12:20:13.531199Z","iopub.status.idle":"2022-05-13T12:20:14.772895Z","shell.execute_reply.started":"2022-05-13T12:20:13.531132Z","shell.execute_reply":"2022-05-13T12:20:14.772106Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:16:47.605409Z","iopub.execute_input":"2022-05-13T12:16:47.607662Z","iopub.status.idle":"2022-05-13T12:16:47.628346Z","shell.execute_reply.started":"2022-05-13T12:16:47.607431Z","shell.execute_reply":"2022-05-13T12:16:47.627017Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data.score.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:20:22.124733Z","iopub.execute_input":"2022-05-13T12:20:22.125257Z","iopub.status.idle":"2022-05-13T12:20:22.135552Z","shell.execute_reply.started":"2022-05-13T12:20:22.125209Z","shell.execute_reply":"2022-05-13T12:20:22.134348Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Setup Train Config","metadata":{}},{"cell_type":"code","source":"# setup TPU \n# Ref - https://gist.github.com/mr-haseeb/c9c01d4a7547e02574d36148b8ca08e4\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Create strategy from tpu\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\nstrategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:45:32.862662Z","iopub.execute_input":"2022-05-13T11:45:32.863210Z","iopub.status.idle":"2022-05-13T11:45:33.184076Z","shell.execute_reply.started":"2022-05-13T11:45:32.863172Z","shell.execute_reply":"2022-05-13T11:45:33.182334Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#TODO - we will enable it after our intial training\n# tf.config.optimizer.set_jit(True) \nclass Config():\n    seed = 42\n    epochs = 10\n    num_folds = 5\n    max_length = 96 # 192\n    batch_size = 16 #64\n    learning_rate = 2e-5\n    weight_decay = 0.01\n    base_model = \"anferico/bert-for-patents\"\n    \n    def __init__(self, **kwargs):\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n    \n#seed_everything(seed=42)\n# strategy = tf.distribute.MirroredStrategy()","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:20:30.776950Z","iopub.execute_input":"2022-05-13T12:20:30.777419Z","iopub.status.idle":"2022-05-13T12:20:30.784907Z","shell.execute_reply.started":"2022-05-13T12:20:30.777386Z","shell.execute_reply":"2022-05-13T12:20:30.783538Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_data['title'] = train_data['title'].str.lower()\ntrain_data['anchor'] = train_data['anchor'].str.lower()\ntrain_data['target'] = train_data['target'].str.lower()\n# Tokenizer.\ntokenizer = transformers.AutoTokenizer.from_pretrained(Config.base_model)\n# Context tokens. \ntrain_data['context_token'] = '[' + train_data.context + ']'\ntrain_data['sep_token'] = '[SEP]'\ntrain_data['cls_token'] = '[CLS]'\ncontext_tokens = list(train_data.context_token.unique())\ntokenizer.add_special_tokens({'additional_special_tokens': context_tokens})\n\n# Preparing input text for the model.\n# We are adding context_token before the context title\n# to let model learn the context of anchor and target.\ntrain_data['text'] = train_data['cls_token'] + \\\n                    train_data['context_token'] + train_data['title'] + \\\n                    train_data['sep_token'] + train_data['anchor'] + \\\n                    train_data['sep_token'] + train_data['target'] + \\\n                train_data['sep_token']","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:20:32.022966Z","iopub.execute_input":"2022-05-13T12:20:32.023342Z","iopub.status.idle":"2022-05-13T12:20:33.474607Z","shell.execute_reply.started":"2022-05-13T12:20:32.023299Z","shell.execute_reply":"2022-05-13T12:20:33.473330Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def encode_text(text, \n                tokenizer,\n                max_length):\n    \n    # With tokenizer's batch_encode_plus batch of both the sentences are\n    # encoded together and separated by [SEP] token.\n    encoded = tokenizer.batch_encode_plus(\n        text,\n        add_special_tokens=False,\n        max_length=max_length,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_token_type_ids=True,\n        return_tensors=\"tf\",\n    )\n\n    # Convert batch of encoded features to numpy array.\n    input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n    attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n    token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_masks\": attention_masks,\n        \"token_type_ids\": token_type_ids\n    }","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:20:33.476872Z","iopub.execute_input":"2022-05-13T12:20:33.477219Z","iopub.status.idle":"2022-05-13T12:20:33.488566Z","shell.execute_reply.started":"2022-05-13T12:20:33.477185Z","shell.execute_reply":"2022-05-13T12:20:33.487334Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Competition Metrics","metadata":{}},{"cell_type":"code","source":"class Pearsonr(tf.keras.callbacks.Callback):\n    def __init__(self, val_data, y_val):\n        self.val_data = val_data\n        self.y_val = y_val\n    def on_epoch_end(self, epoch, logs):\n        val_preds = self.model.predict(self.val_data, verbose=0)\n        \n        val_pearsonr = stats.pearsonr(self.y_val, val_preds.ravel())[0]\n\n        print(f\"val_pearsonr: {val_pearsonr:.4f}\\n\")\n        logs[\"val_pearsonr\"] = val_pearsonr","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:20:34.267210Z","iopub.execute_input":"2022-05-13T12:20:34.267549Z","iopub.status.idle":"2022-05-13T12:20:34.276140Z","shell.execute_reply.started":"2022-05-13T12:20:34.267506Z","shell.execute_reply":"2022-05-13T12:20:34.274742Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Model building","metadata":{}},{"cell_type":"code","source":"def build_model(config, num_train_steps):\n    # Create the model under a distribution strategy scope.\n    #with strategy.scope():\n        # Encoded token ids from BERT tokenizer.\n    input_ids = tf.keras.layers.Input(\n        shape=(config.max_length,), dtype=tf.int32, name=\"input_ids\"\n    )\n    # Attention masks indicates to the model which tokens should be attended to.\n    attention_masks = tf.keras.layers.Input(\n        shape=(config.max_length,), dtype=tf.int32, name=\"attention_masks\"\n    )\n    # Token type ids are binary masks identifying different sequences in the model.\n    token_type_ids = tf.keras.layers.Input(\n        shape=(config.max_length,), dtype=tf.int32, name=\"token_type_ids\"\n    )\n    # Loading pretrained BERT model.\n    base_model = transformers.TFAutoModel.from_pretrained(config.base_model, from_pt=True)\n\n    base_model_output = base_model(\n        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n    )\n\n    last_hidden_state = base_model_output.last_hidden_state\n    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(last_hidden_state)\n    dropout = tf.keras.layers.Dropout(0.3)(avg_pool)\n\n    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(dropout)\n\n    model = tf.keras.models.Model(\n        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n    )\n\n    model.compile(\n        optimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate),\n        loss=tf.keras.losses.BinaryCrossentropy()\n    )\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:20:35.229986Z","iopub.execute_input":"2022-05-13T12:20:35.230365Z","iopub.status.idle":"2022-05-13T12:20:35.243619Z","shell.execute_reply.started":"2022-05-13T12:20:35.230322Z","shell.execute_reply":"2022-05-13T12:20:35.242150Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def train_folds(train, config):\n    oof = np.zeros(len(train))\n    \n    train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n    \n    skf = StratifiedKFold(n_splits=config.num_folds, \n                      shuffle=True,\n                      random_state=config.seed)\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(train, train['score_map'])):\n        print(\"*\" * 25)\n        print(f\"Training fold: {fold+1}\")\n\n        train_df = train.loc[train_idx].reset_index(drop=True)\n        # print(train_df.head(2))\n        val_df = train.loc[val_idx].reset_index(drop=True)\n        \n        # Clear keras session.\n        K.clear_session()\n        \n        train_encoded =  encode_text(train_df[\"text\"].tolist(),\n                                     tokenizer=tokenizer,\n                                     max_length=config.max_length)\n        \n        val_encoded =  encode_text(val_df[\"text\"].tolist(),\n                                     tokenizer=tokenizer,\n                                     max_length=config.max_length)\n        # Dataloader.\n        train_data = tf.data.Dataset.from_tensor_slices((train_encoded, train_df['score'].tolist()))\n        val_data = tf.data.Dataset.from_tensor_slices((val_encoded, val_df['score'].tolist()))\n\n        train_data = (\n                        train_data\n                        .shuffle(1024)\n                        .batch(config.batch_size)\n                        .prefetch(tf.data.AUTOTUNE)\n                     )\n        \n        val_data = (\n                        val_data\n                        .batch(config.batch_size)\n                        .prefetch(tf.data.AUTOTUNE)\n                    )\n\n        # Callbacks.\n        checkpoint = tf.keras.callbacks.ModelCheckpoint(f'model-{fold+1}.h5',\n                                                        monitor='val_loss',\n                                                        mode='min',\n                                                        save_best_only=True,\n                                                        save_weights_only=True,\n                                                        save_freq='epoch',\n                                                        verbose=1)\n        \n        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                          mode='min',\n                                                          patience=3,\n                                                          verbose=1)\n        \n        pearsonr_callback = Pearsonr(val_data, val_df['score'].values)\n        num_train_steps = int(len(train_df) / config.batch_size * config.epochs)\n        \n        # Build and Train model.\n        model = build_model(config, num_train_steps)\n        history = model.fit(\n                        train_data,\n                        validation_data=val_data,\n                        epochs=config.epochs,\n                        callbacks=[checkpoint, \n                                   early_stopping, \n                                   pearsonr_callback],\n                        verbose=1\n                    )\n        \n        print('\\nLoading best model weights...')\n        model.load_weights(f'model-{fold+1}.h5')\n        \n        print('Predicting OOF...')\n        oof[val_idx] = model.predict(val_data,\n                                     batch_size=config.batch_size,\n                                     verbose=0).reshape(-1)\n        \n        \n        score = stats.pearsonr(val_df['score'].values, oof[val_idx])[0]\n        print(f'\\nFold {fold + 1}: OOF pearson_r: {score:.4f}')        \n        print(\"*\" * 25)\n        \n    score = stats.pearsonr(train['score'].values, oof)[0]\n    print(f'\\nOverall OOF pearson_r: {score:.4f}')\n    return oof","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:20:40.438990Z","iopub.execute_input":"2022-05-13T12:20:40.440234Z","iopub.status.idle":"2022-05-13T12:20:40.470839Z","shell.execute_reply.started":"2022-05-13T12:20:40.440130Z","shell.execute_reply":"2022-05-13T12:20:40.469491Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"config = Config()\noof_preds = train_folds(train_data, config)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T12:20:41.454110Z","iopub.execute_input":"2022-05-13T12:20:41.454466Z","iopub.status.idle":"2022-05-13T12:22:22.432949Z","shell.execute_reply.started":"2022-05-13T12:20:41.454423Z","shell.execute_reply":"2022-05-13T12:22:22.430239Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}