{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohameddhameem/kaggle-us-patent-phrase-to-phrase-matching/blob/master/colab-training-v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5om5P901H0Ic",
        "outputId": "e69b2e5e-fb5f-44f8-d3ee-50d4d98750bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.2 MB 34.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 56.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 61.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q2v6ln_oH0Ih"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "#import tensorflow_addons as tfa\n",
        "\n",
        "import transformers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") \n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV7xHiygH0Ii"
      },
      "source": [
        "### Setup TPU or GPU for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JA_O0A9H0Il",
        "outputId": "6947551a-4fbc-4c8c-e0cd-8513b63edb84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we are using Tensorflow version  2.8.0\n",
            "Default GPU Device: /device:GPU:0\n",
            "No TPU detected. Running on GPU / CPU\n",
            "Strategy: <tensorflow.python.distribute.distribute_lib._DefaultDistributionContext object at 0x7fdb0cb3e140>\n"
          ]
        }
      ],
      "source": [
        "print(\"we are using Tensorflow version \", tf.__version__)\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"we are running on CPU. switch to GPU for full training\")\n",
        "\n",
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "except ValueError:\n",
        "    print(\"No TPU detected. Running on GPU / CPU\")\n",
        "    strategy = tf.distribute.get_strategy() \n",
        "\n",
        "print('Strategy:', strategy.scope())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14FoNK6UOdz1",
        "outputId": "cb23fce3-d16e-43f8-c008-fd5ef2b3b225"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/content/drive/MyDrive/Temp')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnEPhPLuOtnn",
        "outputId": "5c9ed199-afad-4446-8bd7-f1c23ddd08a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SG5228 - Individual report_1.docx',\n",
              " 'USPPM-Trained-Model.h5',\n",
              " 'us-patent-phrase-to-phrase-matching']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SoCgUVDrH0In"
      },
      "outputs": [],
      "source": [
        "# read csv files in the us-patent-phrase-to-phrase-matching\n",
        "# directory and store them in a list\n",
        "path = '/content/drive/MyDrive/Temp/us-patent-phrase-to-phrase-matching'\n",
        "files = os.listdir(path)\n",
        "# read the csv files\n",
        "df_train = pd.read_csv(path + '/' + 'train.csv')\n",
        "df_test = pd.read_csv(path + '/' + 'test.csv')\n",
        "df_sample = pd.read_csv(path + '/' + 'sample_submission.csv')\n",
        "parsed = {x: [] for x in ['code', 'title', 'section', 'class', 'subclass', 'group', 'main_group']}\n",
        "os.chdir(path)\n",
        "for letter in 'ABCDEFGHY':\n",
        "    file = f'cpc-section-{letter}_20220201.txt'\n",
        "    with open(file) as f:\n",
        "        for line in f:\n",
        "            vals = line.strip().split('\\t')\n",
        "            if len(vals) == 2:\n",
        "                parsed['code'].append(vals[0])\n",
        "                parsed['title'].append(vals[1])\n",
        "            elif len(vals) == 3:\n",
        "                parsed['code'].append(vals[0])\n",
        "                parsed['title'].append(vals[2])\n",
        "for i in range(len(parsed['code'])):\n",
        "    code = parsed['code'][i]\n",
        "    main_group = code.split('/')[-1] if \"/\" in code else None\n",
        "    group = code.split('/')[0][4:] if len(code) >= 5 else None\n",
        "    subclass = code[3] if len(code) >= 4 else None\n",
        "    class_ = code[1:3] if len(code) >= 3 else None\n",
        "    section = code[0] if len(code) >= 1 else None\n",
        "    \n",
        "    parsed['main_group'].append(main_group)\n",
        "    parsed['group'].append(group)\n",
        "    parsed['subclass'].append(subclass)\n",
        "    parsed['class'].append(class_)\n",
        "    parsed['section'].append(section)\n",
        "\n",
        "\n",
        "# merge both dataframes\n",
        "df_codes = pd.DataFrame.from_dict(parsed)\n",
        "codes = df_codes.rename(columns = {\"code\" : \"context\"})\n",
        "train_data=pd.merge(df_train,codes[[\"context\",\"title\"]],on=\"context\",how=\"left\")\n",
        "test_data=pd.merge(df_test,codes[[\"context\",\"title\"]],on=\"context\",how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINED_MODEL_PATH = '/content/drive/MyDrive/Temp/USPPM-Trained-Model.h5'"
      ],
      "metadata": {
        "id": "hUMGuY0fPq2e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "vBL8M5s5H0Ip"
      },
      "outputs": [],
      "source": [
        "tf.config.optimizer.set_jit(True) \n",
        "class Config():\n",
        "    seed = 42\n",
        "    epochs = 2 # Original 10\n",
        "    num_folds = 2 # Original 5\n",
        "    max_length = 96 # 192 #96 - working - old 192\n",
        "    batch_size = 16 #64 # 16 working. old 64\n",
        "    learning_rate = 2e-5\n",
        "    weight_decay = 0.01\n",
        "    base_model = \"anferico/bert-for-patents\"\n",
        "    \n",
        "    def __init__(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOrB-X5jH0Iq"
      },
      "source": [
        "### Build dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Xb1NWbSvH0Ir"
      },
      "outputs": [],
      "source": [
        "def dataset_split(dataset, split_val):\n",
        "    lengths = int(len(dataset) * split_val)\n",
        "    train_data = dataset[:lengths]\n",
        "    valid_data = dataset[lengths:]\n",
        "    return train_data, valid_data\n",
        "\n",
        "\n",
        "def dataset_load(train_data, test_data):\n",
        "    train_data['sep_token'] = '[SEP]'\n",
        "    train_data['cls_token'] = '[CLS]'\n",
        "    train_data['context_token'] = '[' + train_data.context + ']'\n",
        "    context_tokens = list(train_data.context_token.unique())\n",
        "    train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
        "    train_data, valid_data = dataset_split(dataset=train_data, split_val=0.9)\n",
        "    test_data['sep_token'] = '[SEP]'\n",
        "    test_data['cls_token'] = '[CLS]'\n",
        "    test_data['context_token'] = '[' + test_data.context + ']'\n",
        "    return train_data, valid_data, test_data, context_tokens\n",
        "\n",
        "# create a learning rate scheduler\n",
        "\n",
        "def create_learning_rate_scheduler(max_learn_rate=5e-5,\n",
        "                                   end_learn_rate=1e-7,\n",
        "                                   warmup_epoch_count=10,\n",
        "                                   total_epoch_count=90):\n",
        "\n",
        "    def lr_scheduler(epoch):\n",
        "\n",
        "        if epoch < warmup_epoch_count:\n",
        "            res = (max_learn_rate/warmup_epoch_count) * (epoch + 1)\n",
        "        else:\n",
        "            res = max_learn_rate*math.exp(math.log(end_learn_rate/max_learn_rate)*(\n",
        "                epoch-warmup_epoch_count+1)/(total_epoch_count-warmup_epoch_count+1))\n",
        "        return float(res)\n",
        "    learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
        "        lr_scheduler, verbose=1)\n",
        "\n",
        "    return learning_rate_scheduler\n",
        "\n",
        "\n",
        "def encode_text(text,\n",
        "                tokenizer,\n",
        "                max_length):\n",
        "\n",
        "    # With tokenizer's batch_encode_plus batch of both the sentences are\n",
        "    # encoded together and separated by [SEP] token.\n",
        "    encoded = tokenizer.batch_encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_token_type_ids=True,\n",
        "        return_tensors=\"tf\",\n",
        "    )\n",
        "\n",
        "    # Convert batch of encoded features to numpy array.\n",
        "    input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "    attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "    token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_masks\": attention_masks,\n",
        "        \"token_type_ids\": token_type_ids\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_MEDXRUH0It",
        "outputId": "72bb5484-26bd-4820-ebec-7b15f899c395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23928 2659 36\n",
            "[0.0, 0.25, 0.5, 0.75, 1.0]\n",
            "['[G06]', '[H05]', '[H01]', '[A47]', '[G01]', '[A61]', '[C01]', '[B62]', '[H04]', '[C09]', '[D21]', '[G02]', '[H02]', '[C07]', '[F02]', '[C04]', '[F16]', '[H03]', '[C12]', '[B60]', '[B07]', '[B05]', '[B65]', '[B24]', '[C23]', '[B61]', '[A63]', '[D06]', '[B27]', '[G21]', '[C10]', '[A01]', '[C11]', '[F03]', '[B23]', '[E04]', '[A45]', '[G07]', '[B29]', '[E21]', '[B01]', '[B41]', '[F42]', '[C08]', '[B28]', '[F24]', '[D01]', '[E02]', '[D04]', '[F41]', '[C22]', '[B22]', '[F01]', '[B63]', '[E05]', '[C25]', '[G11]', '[G03]', '[E03]', '[C02]', '[C14]', '[C06]', '[A46]', '[G04]', '[G05]', '[B08]', '[B67]', '[G09]', '[B66]', '[B64]', '[C03]', '[A44]', '[E01]', '[F25]', '[F04]', '[F15]', '[F23]', '[F21]', '[B21]', '[C21]', '[F22]', '[A41]', '[A43]', '[A21]', '[A24]', '[B02]', '[B25]', '[E06]', '[B32]', '[G08]', '[D03]', '[A23]', '[A22]', '[C13]', '[F27]', '[G10]', '[G16]', '[B44]', '[F28]', '[B31]', '[B81]', '[D05]', '[F17]', '[A62]', '[B03]', '[F26]']\n"
          ]
        }
      ],
      "source": [
        "train_data, valid_data, test_data, context_tokens = dataset_load(train_data, test_data)\n",
        "labels = list(set(train_data[\"score\"].values))\n",
        "labels.sort()\n",
        "\n",
        "print(len(train_data), len(valid_data), len(test_data))\n",
        "print(labels)\n",
        "print(context_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "mFWY0uFyH0Iu"
      },
      "outputs": [],
      "source": [
        "train_data['title'] = train_data['title'].str.lower()\n",
        "train_data['anchor'] = train_data['anchor'].str.lower()\n",
        "train_data['target'] = train_data['target'].str.lower()\n",
        "# Tokenizer.\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(Config.base_model)\n",
        "# Context tokens. \n",
        "train_data['context_token'] = '[' + train_data.context + ']'\n",
        "train_data['sep_token'] = '[SEP]'\n",
        "train_data['cls_token'] = '[CLS]'\n",
        "context_tokens = list(train_data.context_token.unique())\n",
        "tokenizer.add_special_tokens({'additional_special_tokens': context_tokens})\n",
        "\n",
        "# Preparing input text for the model.\n",
        "# We are adding context_token before the context title\n",
        "# to let model learn the context of anchor and target.\n",
        "train_data['text'] = train_data['cls_token'] + \\\n",
        "                    train_data['context_token'] + train_data['title'] + \\\n",
        "                    train_data['sep_token'] + train_data['anchor'] + \\\n",
        "                    train_data['sep_token'] + train_data['target'] + \\\n",
        "                train_data['sep_token']\n",
        "\n",
        "test_data['title'] = test_data['title'].str.lower().str.replace(\";\",\"\")\n",
        "test_data['anchor'] = test_data['anchor'].str.lower()\n",
        "test_data['target'] = test_data['target'].str.lower()\n",
        "\n",
        "test_data['text'] = test_data['title'] + \" \" + test_data['anchor']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "PlPrMsSCH0Iv",
        "outputId": "30ef72a1-af28-4ec8-c90e-c25b906ef143"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                       anchor  \\\n",
              "0  4c494b9a7b931791        double planetary gear   \n",
              "1  6e3e3bff3b052674                 opaque walls   \n",
              "2  1434a6f3ecb7d5b3               linear systems   \n",
              "3  6af8fc259b12c843  connect to common conductor   \n",
              "4  17b3e0dae7088276                     mayenite   \n",
              "\n",
              "                          target context  score  \\\n",
              "0    planetary gear transmission     B60   0.50   \n",
              "1            tire truing machine     B29   0.25   \n",
              "2                  rotating tool     B23   0.25   \n",
              "3  common conductor is connected     B66   1.00   \n",
              "4              calcium rich food     B22   0.00   \n",
              "\n",
              "                                               title sep_token cls_token  \\\n",
              "0                                vehicles in general     [SEP]     [CLS]   \n",
              "1  working of plastics; working of substances in ...     [SEP]     [CLS]   \n",
              "2  machine tools; metal-working not otherwise pro...     [SEP]     [CLS]   \n",
              "3                         hoisting; lifting; hauling     [SEP]     [CLS]   \n",
              "4                         casting; powder metallurgy     [SEP]     [CLS]   \n",
              "\n",
              "  context_token                                               text  score_map  \n",
              "0         [B60]  [CLS][B60]vehicles in general[SEP]double plane...          2  \n",
              "1         [B29]  [CLS][B29]working of plastics; working of subs...          1  \n",
              "2         [B23]  [CLS][B23]machine tools; metal-working not oth...          1  \n",
              "3         [B66]  [CLS][B66]hoisting; lifting; hauling[SEP]conne...          4  \n",
              "4         [B22]  [CLS][B22]casting; powder metallurgy[SEP]mayen...          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e403e5a-545f-4223-b089-7932daeb84e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "      <th>title</th>\n",
              "      <th>sep_token</th>\n",
              "      <th>cls_token</th>\n",
              "      <th>context_token</th>\n",
              "      <th>text</th>\n",
              "      <th>score_map</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4c494b9a7b931791</td>\n",
              "      <td>double planetary gear</td>\n",
              "      <td>planetary gear transmission</td>\n",
              "      <td>B60</td>\n",
              "      <td>0.50</td>\n",
              "      <td>vehicles in general</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[B60]</td>\n",
              "      <td>[CLS][B60]vehicles in general[SEP]double plane...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6e3e3bff3b052674</td>\n",
              "      <td>opaque walls</td>\n",
              "      <td>tire truing machine</td>\n",
              "      <td>B29</td>\n",
              "      <td>0.25</td>\n",
              "      <td>working of plastics; working of substances in ...</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[B29]</td>\n",
              "      <td>[CLS][B29]working of plastics; working of subs...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1434a6f3ecb7d5b3</td>\n",
              "      <td>linear systems</td>\n",
              "      <td>rotating tool</td>\n",
              "      <td>B23</td>\n",
              "      <td>0.25</td>\n",
              "      <td>machine tools; metal-working not otherwise pro...</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[B23]</td>\n",
              "      <td>[CLS][B23]machine tools; metal-working not oth...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6af8fc259b12c843</td>\n",
              "      <td>connect to common conductor</td>\n",
              "      <td>common conductor is connected</td>\n",
              "      <td>B66</td>\n",
              "      <td>1.00</td>\n",
              "      <td>hoisting; lifting; hauling</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[B66]</td>\n",
              "      <td>[CLS][B66]hoisting; lifting; hauling[SEP]conne...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17b3e0dae7088276</td>\n",
              "      <td>mayenite</td>\n",
              "      <td>calcium rich food</td>\n",
              "      <td>B22</td>\n",
              "      <td>0.00</td>\n",
              "      <td>casting; powder metallurgy</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[B22]</td>\n",
              "      <td>[CLS][B22]casting; powder metallurgy[SEP]mayen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e403e5a-545f-4223-b089-7932daeb84e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e403e5a-545f-4223-b089-7932daeb84e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e403e5a-545f-4223-b089-7932daeb84e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "lcr8MAAGH0Iw",
        "outputId": "65638f49-3693-4046-8124-250ba5ff85c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id              anchor                         target  \\\n",
              "0  4112d61851461f60            opc drum  inorganic photoconductor drum   \n",
              "1  09e418c93a776564     adjust gas flow              altering gas flow   \n",
              "2  36baf228038e314b      lower trunnion                 lower locating   \n",
              "3  1f37ead645e7f0c8       cap component                  upper portion   \n",
              "4  71a5b6ad068d531f  neural stimulation      artificial neural network   \n",
              "\n",
              "  context                                              title sep_token  \\\n",
              "0     G02                                             optics     [SEP]   \n",
              "1     F23          combustion apparatus combustion processes     [SEP]   \n",
              "2     B60                                vehicles in general     [SEP]   \n",
              "3     D06  treatment of textiles or the like laundering f...     [SEP]   \n",
              "4     H04                   electric communication technique     [SEP]   \n",
              "\n",
              "  cls_token context_token                                               text  \n",
              "0     [CLS]         [G02]                                    optics opc drum  \n",
              "1     [CLS]         [F23]  combustion apparatus combustion processes adju...  \n",
              "2     [CLS]         [B60]                 vehicles in general lower trunnion  \n",
              "3     [CLS]         [D06]  treatment of textiles or the like laundering f...  \n",
              "4     [CLS]         [H04]  electric communication technique neural stimul...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b707aa16-e3e6-4540-a470-f0d88127a03e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "      <th>sep_token</th>\n",
              "      <th>cls_token</th>\n",
              "      <th>context_token</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4112d61851461f60</td>\n",
              "      <td>opc drum</td>\n",
              "      <td>inorganic photoconductor drum</td>\n",
              "      <td>G02</td>\n",
              "      <td>optics</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[G02]</td>\n",
              "      <td>optics opc drum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>09e418c93a776564</td>\n",
              "      <td>adjust gas flow</td>\n",
              "      <td>altering gas flow</td>\n",
              "      <td>F23</td>\n",
              "      <td>combustion apparatus combustion processes</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[F23]</td>\n",
              "      <td>combustion apparatus combustion processes adju...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36baf228038e314b</td>\n",
              "      <td>lower trunnion</td>\n",
              "      <td>lower locating</td>\n",
              "      <td>B60</td>\n",
              "      <td>vehicles in general</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[B60]</td>\n",
              "      <td>vehicles in general lower trunnion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1f37ead645e7f0c8</td>\n",
              "      <td>cap component</td>\n",
              "      <td>upper portion</td>\n",
              "      <td>D06</td>\n",
              "      <td>treatment of textiles or the like laundering f...</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[D06]</td>\n",
              "      <td>treatment of textiles or the like laundering f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71a5b6ad068d531f</td>\n",
              "      <td>neural stimulation</td>\n",
              "      <td>artificial neural network</td>\n",
              "      <td>H04</td>\n",
              "      <td>electric communication technique</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[H04]</td>\n",
              "      <td>electric communication technique neural stimul...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b707aa16-e3e6-4540-a470-f0d88127a03e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b707aa16-e3e6-4540-a470-f0d88127a03e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b707aa16-e3e6-4540-a470-f0d88127a03e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "xsTf2Rz2H0Iw"
      },
      "outputs": [],
      "source": [
        "encoded_test_data = encode_text(test_data[[\"text\", \"target\"]].values.tolist(), tokenizer, Config.max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQTzqbhYH0Ix",
        "outputId": "897420e9-8c50-48c6-dfe8-c7f8bc752db9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    2 20691  6393  1943  6608     3 27921  5967  8328  8231 16426  6608\n",
            "     3     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "print(encoded_test_data[\"input_ids\"][0])\n",
        "print(encoded_test_data[\"attention_masks\"][0])\n",
        "print(encoded_test_data[\"token_type_ids\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r-wc3zXH0Iy",
        "outputId": "08445c4f-36da-4ce4-c89d-5464bd7a7518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test x shape :  (36, 96) (36, 96) (36, 96)\n"
          ]
        }
      ],
      "source": [
        "test_x = [encoded_test_data[\"input_ids\"], encoded_test_data[\"attention_masks\"], encoded_test_data[\"token_type_ids\"]]\n",
        "print(\"test x shape : \", test_x[0].shape, test_x[1].shape, test_x[2].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "YT4G5KDYH0Iy"
      },
      "outputs": [],
      "source": [
        "def build_model(config):\n",
        "    # Create the model under a distribution strategy scope.\n",
        "    with strategy.scope():\n",
        "        # Encoded token ids from BERT tokenizer.\n",
        "        input_ids = tf.keras.layers.Input(\n",
        "            shape=(config.max_length,), dtype=tf.int32, name=\"input_ids\"\n",
        "        )\n",
        "        # Attention masks indicates to the model which tokens should be attended to.\n",
        "        attention_masks = tf.keras.layers.Input(\n",
        "            shape=(config.max_length,), dtype=tf.int32, name=\"attention_masks\"\n",
        "        )\n",
        "        # Token type ids are binary masks identifying different sequences in the model.\n",
        "        token_type_ids = tf.keras.layers.Input(\n",
        "            shape=(config.max_length,), dtype=tf.int32, name=\"token_type_ids\"\n",
        "        )\n",
        "        # Loading pretrained BERT model.\n",
        "        base_model = transformers.TFAutoModel.from_pretrained(config.base_model, from_pt=True)\n",
        "\n",
        "        base_model_output = base_model(\n",
        "            input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        last_hidden_state = base_model_output.last_hidden_state\n",
        "        avg_pool = tf.keras.layers.GlobalAveragePooling1D()(last_hidden_state)\n",
        "        dropout = tf.keras.layers.Dropout(0.3)(avg_pool)\n",
        "\n",
        "        output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(dropout)\n",
        "\n",
        "        model = tf.keras.models.Model(\n",
        "            inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n",
        "        )\n",
        "\n",
        "        model.compile(\n",
        "            optimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate),\n",
        "            loss=tf.keras.losses.BinaryCrossentropy()\n",
        "        )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics for Competition"
      ],
      "metadata": {
        "id": "XZ0NPrmRL81F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Pearsonr(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, val_data, y_val):\n",
        "        self.val_data = val_data\n",
        "        self.y_val = y_val\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        val_preds = self.model.predict(self.val_data, verbose=0)\n",
        "        \n",
        "        val_pearsonr = stats.pearsonr(self.y_val, val_preds.ravel())[0]\n",
        "\n",
        "        print(f\"val_pearsonr: {val_pearsonr:.4f}\\n\")\n",
        "        logs[\"val_pearsonr\"] = val_pearsonr"
      ],
      "metadata": {
        "id": "RNrp-cBsL8EJ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model K Fold Training\n",
        "Use previously trained weight first"
      ],
      "metadata": {
        "id": "gymdq4e1Kury"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_folds(train, config):\n",
        "    oof = np.zeros(len(train))\n",
        "    pretrained_model_loaded = False\n",
        "    train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n",
        "    \n",
        "    skf = StratifiedKFold(n_splits=config.num_folds, \n",
        "                      shuffle=True,\n",
        "                      random_state=config.seed)\n",
        "    \n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(train, train['score_map'])):\n",
        "        print(\"*\" * 50)\n",
        "        print(f\"Training fold: {fold+1}\")\n",
        "\n",
        "        train_df = train.loc[train_idx].reset_index(drop=True)\n",
        "        # print(train_df.head(2))\n",
        "        val_df = train.loc[val_idx].reset_index(drop=True)\n",
        "        \n",
        "        # Clear keras session.\n",
        "        K.clear_session()\n",
        "        \n",
        "        train_encoded =  encode_text(train_df[\"text\"].tolist(),\n",
        "                                     tokenizer=tokenizer,\n",
        "                                     max_length=config.max_length)\n",
        "        \n",
        "        val_encoded =  encode_text(val_df[\"text\"].tolist(),\n",
        "                                     tokenizer=tokenizer,\n",
        "                                     max_length=config.max_length)\n",
        "        # Dataloader.\n",
        "        train_data = tf.data.Dataset.from_tensor_slices((train_encoded, train_df['score'].tolist()))\n",
        "        val_data = tf.data.Dataset.from_tensor_slices((val_encoded, val_df['score'].tolist()))\n",
        "\n",
        "        train_data = (\n",
        "                        train_data\n",
        "                        .shuffle(1024)\n",
        "                        .batch(config.batch_size)\n",
        "                        .prefetch(tf.data.AUTOTUNE)\n",
        "                     )\n",
        "        \n",
        "        val_data = (\n",
        "                        val_data\n",
        "                        .batch(config.batch_size)\n",
        "                        .prefetch(tf.data.AUTOTUNE)\n",
        "                    )\n",
        "\n",
        "        # Callbacks.\n",
        "        checkpoint = tf.keras.callbacks.ModelCheckpoint(f'model-{fold+1}.h5',\n",
        "                                                        monitor='val_loss',\n",
        "                                                        mode='min',\n",
        "                                                        save_best_only=True,\n",
        "                                                        save_weights_only=True,\n",
        "                                                        save_freq='epoch',\n",
        "                                                        verbose=1)\n",
        "        \n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                          mode='min',\n",
        "                                                          patience=3,\n",
        "                                                          verbose=1)\n",
        "        \n",
        "        pearsonr_callback = Pearsonr(val_data, val_df['score'].values)\n",
        "        num_train_steps = int(len(train_df) / config.batch_size * config.epochs)\n",
        "        \n",
        "        # Build and Train model.\n",
        "        model = build_model(config) #, num_train_steps\n",
        "        # for the first time in Colab load the pretrained model\n",
        "        if pretrained_model_loaded == False:\n",
        "          model.load_weights(TRAINED_MODEL_PATH)\n",
        "          pretrained_model_loaded = True\n",
        "          print(\"Our own pretrained model loaded......\")\n",
        "        history = model.fit(\n",
        "                        train_data,\n",
        "                        validation_data=val_data,\n",
        "                        epochs=config.epochs,\n",
        "                        callbacks=[checkpoint, \n",
        "                                   early_stopping, \n",
        "                                   pearsonr_callback],\n",
        "                        verbose=1\n",
        "                    )\n",
        "        \n",
        "        print('\\nLoading best model weights...')\n",
        "        model.load_weights(f'model-{fold+1}.h5')\n",
        "        \n",
        "        print('Predicting OOF...')\n",
        "        oof[val_idx] = model.predict(val_data,\n",
        "                                     batch_size=config.batch_size,\n",
        "                                     verbose=0).reshape(-1)\n",
        "        \n",
        "        \n",
        "        score = stats.pearsonr(val_df['score'].values, oof[val_idx])[0]\n",
        "        print(f'\\nFold {fold + 1}: OOF pearson_r: {score:.4f}')        \n",
        "        print(\"*\" * 25)\n",
        "        \n",
        "    score = stats.pearsonr(train['score'].values, oof)[0]\n",
        "    print(f'\\nOverall OOF pearson_r: {score:.4f}')\n",
        "    return oof"
      ],
      "metadata": {
        "id": "BculjIqkK0cU"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8nh8nzyiH0Iz",
        "outputId": "93b970a8-4b21-4de5-ad80-41a01c2ab266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************\n",
            "Training fold: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.embeddings.position_ids', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our own pretrained model loaded......\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-419bc4c32475>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moof_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-63-187249bbf30c>\u001b[0m in \u001b[0;36mtrain_folds\u001b[0;34m(train, config)\u001b[0m\n\u001b[1;32m     74\u001b[0m                                    \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                                    pearsonr_callback],\n\u001b[0;32m---> 76\u001b[0;31m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                     )\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nOut of memory while trying to allocate 25165824 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   50.03MiB\n              constant allocation:        56B\n        maybe_live_out allocation:  170.02MiB\n     preallocated temp allocation:       216B\n                 total allocation:  188.04MiB\n              total fragmentation:       296B (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 24.00MiB\n\t\tOperator: op_type=\"Reshape\" op_name=\"model/tf_bert_model/bert/encoder/layer_._18/output/dense/Tensordot/Reshape\"\n\t\tXLA Label: fusion\n\t\tShape: f32[1536,4096]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 24.00MiB\n\t\tOperator: op_type=\"AddV2\" op_name=\"model/tf_bert_model/bert/encoder/layer_._18/intermediate/Gelu/add\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,4096]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 24.00MiB\n\t\tOperator: op_type=\"AddV2\" op_name=\"model/tf_bert_model/bert/encoder/layer_._18/intermediate/Gelu/add\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,4096]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 24.00MiB\n\t\tOperator: op_type=\"AddV2\" op_name=\"model/tf_bert_model/bert/encoder/layer_._18/intermediate/Gelu/add\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,4096]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 16.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tEntry Parameter Subshape: f32[4096,1024]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 16.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tEntry Parameter Subshape: f32[1024,4096]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 6.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tEntry Parameter Subshape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 6.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tEntry Parameter Subshape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 6.00MiB\n\t\tXLA Label: copy\n\t\tShape: f32[1536,1024]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 6.00MiB\n\t\tOperator: op_type=\"BiasAdd\" op_name=\"model/tf_bert_model/bert/encoder/layer_._18/output/dense/BiasAdd\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 6.00MiB\n\t\tOperator: op_type=\"AddV2\" op_name=\"model/tf_bert_model/bert/encoder/layer_._18/attention/output/LayerNorm/batchnorm/add_1\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 6.00MiB\n\t\tOperator: op_type=\"AddV2\" op_name=\"model/tf_bert_model/bert/encoder/layer_._18/attention/output/LayerNorm/batchnorm/add_1\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 6.00MiB\n\t\tOperator: op_type=\"Mean\" op_name=\"model/tf_bert_model/bert/encoder/layer_._18/attention/output/LayerNorm/moments/variance\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 6.00MiB\n\t\tOperator: op_type=\"Mean\" op_name=\"model/tf_bert_model/bert/encoder/layer_._18/attention/output/LayerNorm/moments/mean\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 6.00MiB\n\t\tOperator: op_type=\"Mean\" op_name=\"model/tf_bert_model/bert/encoder/layer_._18/attention/output/LayerNorm/moments/mean\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,1024]\n\t\t==========================\n\n\n\t [[{{node cluster_356_1/xla_run}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_268431]"
          ]
        }
      ],
      "source": [
        "config = Config()\n",
        "oof_preds = train_folds(train_data, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KdR2RYLH0Iz"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "model.load_weights('model-2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWa4C0IxH0I0"
      },
      "outputs": [],
      "source": [
        "# Lets predict the test data.\n",
        "predictions = model.predict(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38Q0Pv_QH0I0"
      },
      "outputs": [],
      "source": [
        "# Lets read sample submission file.\n",
        "submission = pd.read_csv('sample_submission.csv')\n",
        "submission['score'] = predictions\n",
        "submission['score'] = submission.score.apply(lambda x: 0 if x < 0 else x)\n",
        "submission['score'] = submission.score.apply(lambda x: 1 if x > 1 else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19WKauexH0I1",
        "outputId": "1f5e4d8c-7544-4eb5-d550-bac3863449eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4112d61851461f60</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>09e418c93a776564</td>\n",
              "      <td>0.363816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36baf228038e314b</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1f37ead645e7f0c8</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71a5b6ad068d531f</td>\n",
              "      <td>0.363816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>474c874d0c07bd21</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>442c114ed5c4e3c9</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>b8ae62ea5e1d8bdb</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>faaddaf8fcba8a3f</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ae0262c02566d2ce</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>a8808e31641e856d</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>16ae4b99d3601e60</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>25c555ca3d5a2092</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>5203a36c501f1b7c</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>b9fdc772bb8fd61c</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7aa5908a77a7ec24</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>d19ef3979396d47e</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>fd83613b7843f5e1</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2a619016908bfa45</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>733979d75f59770d</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6546846df17f9800</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3ff0e7a35015be69</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>12ca31f018a2e2b9</td>\n",
              "      <td>0.363816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>03ba802ed4029e4d</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>c404f8b378cbb008</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>78243984c02a72e4</td>\n",
              "      <td>0.363813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>de51114bc0faec3e</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>7e3aff857f056bf9</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>26c3c6dc6174b589</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>b892011ab2e2cabc</td>\n",
              "      <td>0.363816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>8247ff562ca185cc</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>c057aecbba832387</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>9f2279ce667b21dc</td>\n",
              "      <td>0.363816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>b9ea2b06a878df6f</td>\n",
              "      <td>0.363816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>79795133c30ef097</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>25522ee5411e63e9</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id     score\n",
              "0   4112d61851461f60  0.363815\n",
              "1   09e418c93a776564  0.363816\n",
              "2   36baf228038e314b  0.363814\n",
              "3   1f37ead645e7f0c8  0.363814\n",
              "4   71a5b6ad068d531f  0.363816\n",
              "5   474c874d0c07bd21  0.363815\n",
              "6   442c114ed5c4e3c9  0.363815\n",
              "7   b8ae62ea5e1d8bdb  0.363815\n",
              "8   faaddaf8fcba8a3f  0.363815\n",
              "9   ae0262c02566d2ce  0.363815\n",
              "10  a8808e31641e856d  0.363815\n",
              "11  16ae4b99d3601e60  0.363815\n",
              "12  25c555ca3d5a2092  0.363815\n",
              "13  5203a36c501f1b7c  0.363815\n",
              "14  b9fdc772bb8fd61c  0.363815\n",
              "15  7aa5908a77a7ec24  0.363815\n",
              "16  d19ef3979396d47e  0.363815\n",
              "17  fd83613b7843f5e1  0.363814\n",
              "18  2a619016908bfa45  0.363815\n",
              "19  733979d75f59770d  0.363815\n",
              "20  6546846df17f9800  0.363815\n",
              "21  3ff0e7a35015be69  0.363814\n",
              "22  12ca31f018a2e2b9  0.363816\n",
              "23  03ba802ed4029e4d  0.363814\n",
              "24  c404f8b378cbb008  0.363815\n",
              "25  78243984c02a72e4  0.363813\n",
              "26  de51114bc0faec3e  0.363815\n",
              "27  7e3aff857f056bf9  0.363814\n",
              "28  26c3c6dc6174b589  0.363814\n",
              "29  b892011ab2e2cabc  0.363816\n",
              "30  8247ff562ca185cc  0.363814\n",
              "31  c057aecbba832387  0.363815\n",
              "32  9f2279ce667b21dc  0.363816\n",
              "33  b9ea2b06a878df6f  0.363816\n",
              "34  79795133c30ef097  0.363815\n",
              "35  25522ee5411e63e9  0.363815"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission.to_csv(\"submission.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz6zmOZtH0I1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "24ffb122db4d293cbce3a5b97151e6069f3c74d2302b3d157e23222a76757a60"
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 ('kaggle-nlp')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "colab-training-v2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}