{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohameddhameem/kaggle-us-patent-phrase-to-phrase-matching/blob/master/colab-training-v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5om5P901H0Ic"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q2v6ln_oH0Ih"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "#import tensorflow_addons as tfa\n",
        "\n",
        "import transformers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") \n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV7xHiygH0Ii"
      },
      "source": [
        "### Setup TPU or GPU for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JA_O0A9H0Il",
        "outputId": "9ad415c8-cbb2-40a9-c3d2-8664398c0da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we are using Tensorflow version  2.8.0\n",
            "Default GPU Device: /device:GPU:0\n",
            "No TPU detected. Running on GPU / CPU\n",
            "Strategy: <tensorflow.python.distribute.distribute_lib._DefaultDistributionContext object at 0x7f8de7bf57d0>\n"
          ]
        }
      ],
      "source": [
        "print(\"we are using Tensorflow version \", tf.__version__)\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"we are running on CPU. switch to GPU for full training\")\n",
        "\n",
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "except ValueError:\n",
        "    print(\"No TPU detected. Running on GPU / CPU\")\n",
        "    strategy = tf.distribute.get_strategy() \n",
        "\n",
        "print('Strategy:', strategy.scope())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14FoNK6UOdz1",
        "outputId": "4a2b0c3a-71e0-41e5-f63a-f8c31804bd35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/content/drive/MyDrive/Temp')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnEPhPLuOtnn",
        "outputId": "3b33ac40-4c07-4e20-c61a-e02069f3234c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SG5228 - Individual report_1.docx',\n",
              " 'USPPM-Trained-Model.h5',\n",
              " 'us-patent-phrase-to-phrase-matching']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SoCgUVDrH0In"
      },
      "outputs": [],
      "source": [
        "# read csv files in the us-patent-phrase-to-phrase-matching\n",
        "# directory and store them in a list\n",
        "path = '/content/drive/MyDrive/Temp/us-patent-phrase-to-phrase-matching'\n",
        "files = os.listdir(path)\n",
        "# read the csv files\n",
        "df_train = pd.read_csv(path + '/' + 'train.csv')\n",
        "df_test = pd.read_csv(path + '/' + 'test.csv')\n",
        "df_sample = pd.read_csv(path + '/' + 'sample_submission.csv')\n",
        "parsed = {x: [] for x in ['code', 'title', 'section', 'class', 'subclass', 'group', 'main_group']}\n",
        "os.chdir(path)\n",
        "for letter in 'ABCDEFGHY':\n",
        "    file = f'cpc-section-{letter}_20220201.txt'\n",
        "    with open(file) as f:\n",
        "        for line in f:\n",
        "            vals = line.strip().split('\\t')\n",
        "            if len(vals) == 2:\n",
        "                parsed['code'].append(vals[0])\n",
        "                parsed['title'].append(vals[1])\n",
        "            elif len(vals) == 3:\n",
        "                parsed['code'].append(vals[0])\n",
        "                parsed['title'].append(vals[2])\n",
        "for i in range(len(parsed['code'])):\n",
        "    code = parsed['code'][i]\n",
        "    main_group = code.split('/')[-1] if \"/\" in code else None\n",
        "    group = code.split('/')[0][4:] if len(code) >= 5 else None\n",
        "    subclass = code[3] if len(code) >= 4 else None\n",
        "    class_ = code[1:3] if len(code) >= 3 else None\n",
        "    section = code[0] if len(code) >= 1 else None\n",
        "    \n",
        "    parsed['main_group'].append(main_group)\n",
        "    parsed['group'].append(group)\n",
        "    parsed['subclass'].append(subclass)\n",
        "    parsed['class'].append(class_)\n",
        "    parsed['section'].append(section)\n",
        "\n",
        "\n",
        "# merge both dataframes\n",
        "df_codes = pd.DataFrame.from_dict(parsed)\n",
        "codes = df_codes.rename(columns = {\"code\" : \"context\"})\n",
        "train_data=pd.merge(df_train,codes[[\"context\",\"title\"]],on=\"context\",how=\"left\")\n",
        "test_data=pd.merge(df_test,codes[[\"context\",\"title\"]],on=\"context\",how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINED_MODEL_PATH = '/content/drive/MyDrive/Temp/USPPM-Trained-Model.h5'"
      ],
      "metadata": {
        "id": "hUMGuY0fPq2e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vBL8M5s5H0Ip"
      },
      "outputs": [],
      "source": [
        "tf.config.optimizer.set_jit(True) \n",
        "class Config():\n",
        "    seed = 42\n",
        "    epochs = 10 # Original 10\n",
        "    num_folds = 5 # Original 5\n",
        "    max_length = 96 # 192 #96 - working - old 192\n",
        "    batch_size = 16 #64 # 16 working. old 64\n",
        "    learning_rate = 2e-5\n",
        "    weight_decay = 0.01\n",
        "    base_model = \"anferico/bert-for-patents\"\n",
        "    \n",
        "    def __init__(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOrB-X5jH0Iq"
      },
      "source": [
        "### Build dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Xb1NWbSvH0Ir"
      },
      "outputs": [],
      "source": [
        "def dataset_split(dataset, split_val):\n",
        "    lengths = int(len(dataset) * split_val)\n",
        "    train_data = dataset[:lengths]\n",
        "    valid_data = dataset[lengths:]\n",
        "    return train_data, valid_data\n",
        "\n",
        "\n",
        "def dataset_load(train_data, test_data):\n",
        "    train_data['sep_token'] = '[SEP]'\n",
        "    train_data['cls_token'] = '[CLS]'\n",
        "    train_data['context_token'] = '[' + train_data.context + ']'\n",
        "    context_tokens = list(train_data.context_token.unique())\n",
        "    train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
        "    train_data, valid_data = dataset_split(dataset=train_data, split_val=0.9)\n",
        "    test_data['sep_token'] = '[SEP]'\n",
        "    test_data['cls_token'] = '[CLS]'\n",
        "    test_data['context_token'] = '[' + test_data.context + ']'\n",
        "    return train_data, valid_data, test_data, context_tokens\n",
        "\n",
        "# create a learning rate scheduler\n",
        "\n",
        "def create_learning_rate_scheduler(max_learn_rate=5e-5,\n",
        "                                   end_learn_rate=1e-7,\n",
        "                                   warmup_epoch_count=10,\n",
        "                                   total_epoch_count=90):\n",
        "\n",
        "    def lr_scheduler(epoch):\n",
        "\n",
        "        if epoch < warmup_epoch_count:\n",
        "            res = (max_learn_rate/warmup_epoch_count) * (epoch + 1)\n",
        "        else:\n",
        "            res = max_learn_rate*math.exp(math.log(end_learn_rate/max_learn_rate)*(\n",
        "                epoch-warmup_epoch_count+1)/(total_epoch_count-warmup_epoch_count+1))\n",
        "        return float(res)\n",
        "    learning_rate_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
        "        lr_scheduler, verbose=1)\n",
        "\n",
        "    return learning_rate_scheduler\n",
        "\n",
        "\n",
        "def encode_text(text,\n",
        "                tokenizer,\n",
        "                max_length):\n",
        "\n",
        "    # With tokenizer's batch_encode_plus batch of both the sentences are\n",
        "    # encoded together and separated by [SEP] token.\n",
        "    encoded = tokenizer.batch_encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_token_type_ids=True,\n",
        "        return_tensors=\"tf\",\n",
        "    )\n",
        "\n",
        "    # Convert batch of encoded features to numpy array.\n",
        "    input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "    attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "    token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_masks\": attention_masks,\n",
        "        \"token_type_ids\": token_type_ids\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_MEDXRUH0It",
        "outputId": "1adcef2d-28ed-4e84-9ae4-4d2c1cf10ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32825 3648 36\n",
            "[0.0, 0.25, 0.5, 0.75, 1.0]\n",
            "['[A47]', '[A61]', '[A62]', '[C01]', '[F16]', '[F24]', '[F28]', '[H01]', '[H04]', '[B23]', '[B41]', '[D03]', '[E03]', '[C08]', '[D01]', '[D21]', '[C07]', '[A45]', '[B01]', '[B08]', '[G04]', '[G06]', '[B65]', '[G16]', '[G01]', '[A41]', '[C23]', '[F23]', '[B25]', '[A63]', '[B28]', '[B63]', '[F04]', '[B60]', '[B32]', '[C09]', '[C02]', '[G03]', '[C10]', '[B61]', '[C21]', '[F42]', '[A23]', '[C11]', '[B29]', '[F02]', '[B62]', '[B64]', '[E21]', '[B24]', '[B22]', '[H05]', '[B27]', '[E04]', '[B21]', '[D06]', '[C04]', '[B05]', '[G02]', '[H03]', '[C06]', '[G11]', '[C12]', '[E02]', '[F15]', '[A46]', '[B66]', '[G07]', '[G08]', '[C22]', '[B44]', '[A01]', '[F03]', '[C25]', '[F22]', '[G05]', '[G21]', '[B07]', '[F41]', '[E01]', '[H02]', '[C13]', '[F01]', '[F27]', '[C14]', '[A44]', '[B67]', '[A24]', '[B02]', '[E05]', '[D05]', '[F25]', '[A43]', '[A22]', '[A21]', '[E06]', '[F21]', '[G10]', '[C03]', '[B81]', '[F17]', '[B03]', '[G09]', '[D04]', '[F26]', '[B31]']\n"
          ]
        }
      ],
      "source": [
        "train_data, valid_data, test_data, context_tokens = dataset_load(train_data, test_data)\n",
        "labels = list(set(train_data[\"score\"].values))\n",
        "labels.sort()\n",
        "\n",
        "print(len(train_data), len(valid_data), len(test_data))\n",
        "print(labels)\n",
        "print(context_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "mFWY0uFyH0Iu"
      },
      "outputs": [],
      "source": [
        "train_data['title'] = train_data['title'].str.lower()\n",
        "train_data['anchor'] = train_data['anchor'].str.lower()\n",
        "train_data['target'] = train_data['target'].str.lower()\n",
        "# Tokenizer.\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(Config.base_model)\n",
        "# Context tokens. \n",
        "train_data['context_token'] = '[' + train_data.context + ']'\n",
        "train_data['sep_token'] = '[SEP]'\n",
        "train_data['cls_token'] = '[CLS]'\n",
        "context_tokens = list(train_data.context_token.unique())\n",
        "tokenizer.add_special_tokens({'additional_special_tokens': context_tokens})\n",
        "\n",
        "# Preparing input text for the model.\n",
        "# We are adding context_token before the context title\n",
        "# to let model learn the context of anchor and target.\n",
        "train_data['text'] = train_data['cls_token'] + \\\n",
        "                    train_data['context_token'] + train_data['title'] + \\\n",
        "                    train_data['sep_token'] + train_data['anchor'] + \\\n",
        "                    train_data['sep_token'] + train_data['target'] + \\\n",
        "                train_data['sep_token']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "PlPrMsSCH0Iv",
        "outputId": "0160f041-648b-496e-b83b-907525459e94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                  anchor                          target  \\\n",
              "0  2dff11db0ed774bf          comfortability                    foot wearing   \n",
              "1  828710db181225e6         decreased power            temporary transition   \n",
              "2  ae777f570846aa11  high frequency welding              stabilizing device   \n",
              "3  775d5063e3f48890             vacuum cups             vacuum cup assembly   \n",
              "4  9c7a87a3b9ad9172      synthetic training  device classification training   \n",
              "\n",
              "  context  score                                              title sep_token  \\\n",
              "0     A41   0.00                                    wearing apparel     [SEP]   \n",
              "1     H01   0.25                            basic electric elements     [SEP]   \n",
              "2     B65   0.25  conveying; packing; storing; handling thin or ...     [SEP]   \n",
              "3     E01   0.75        construction of roads, railways, or bridges     [SEP]   \n",
              "4     G06   0.50                   computing; calculating; counting     [SEP]   \n",
              "\n",
              "  cls_token context_token                                               text  \\\n",
              "0     [CLS]         [A41]  [CLS][A41]wearing apparel[SEP]comfortability[S...   \n",
              "1     [CLS]         [H01]  [CLS][H01]basic electric elements[SEP]decrease...   \n",
              "2     [CLS]         [B65]  [CLS][B65]conveying; packing; storing; handlin...   \n",
              "3     [CLS]         [E01]  [CLS][E01]construction of roads, railways, or ...   \n",
              "4     [CLS]         [G06]  [CLS][G06]computing; calculating; counting[SEP...   \n",
              "\n",
              "   score_map  \n",
              "0          0  \n",
              "1          1  \n",
              "2          1  \n",
              "3          3  \n",
              "4          2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa730340-e0fd-48ec-ac58-292f1ff8536d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "      <th>title</th>\n",
              "      <th>sep_token</th>\n",
              "      <th>cls_token</th>\n",
              "      <th>context_token</th>\n",
              "      <th>text</th>\n",
              "      <th>score_map</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2dff11db0ed774bf</td>\n",
              "      <td>comfortability</td>\n",
              "      <td>foot wearing</td>\n",
              "      <td>A41</td>\n",
              "      <td>0.00</td>\n",
              "      <td>wearing apparel</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[A41]</td>\n",
              "      <td>[CLS][A41]wearing apparel[SEP]comfortability[S...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>828710db181225e6</td>\n",
              "      <td>decreased power</td>\n",
              "      <td>temporary transition</td>\n",
              "      <td>H01</td>\n",
              "      <td>0.25</td>\n",
              "      <td>basic electric elements</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[H01]</td>\n",
              "      <td>[CLS][H01]basic electric elements[SEP]decrease...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ae777f570846aa11</td>\n",
              "      <td>high frequency welding</td>\n",
              "      <td>stabilizing device</td>\n",
              "      <td>B65</td>\n",
              "      <td>0.25</td>\n",
              "      <td>conveying; packing; storing; handling thin or ...</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[B65]</td>\n",
              "      <td>[CLS][B65]conveying; packing; storing; handlin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>775d5063e3f48890</td>\n",
              "      <td>vacuum cups</td>\n",
              "      <td>vacuum cup assembly</td>\n",
              "      <td>E01</td>\n",
              "      <td>0.75</td>\n",
              "      <td>construction of roads, railways, or bridges</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[E01]</td>\n",
              "      <td>[CLS][E01]construction of roads, railways, or ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9c7a87a3b9ad9172</td>\n",
              "      <td>synthetic training</td>\n",
              "      <td>device classification training</td>\n",
              "      <td>G06</td>\n",
              "      <td>0.50</td>\n",
              "      <td>computing; calculating; counting</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[G06]</td>\n",
              "      <td>[CLS][G06]computing; calculating; counting[SEP...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa730340-e0fd-48ec-ac58-292f1ff8536d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa730340-e0fd-48ec-ac58-292f1ff8536d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa730340-e0fd-48ec-ac58-292f1ff8536d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "lcr8MAAGH0Iw",
        "outputId": "db740b1b-9705-4e0c-b3be-1197a44e9f48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id              anchor                         target  \\\n",
              "0  4112d61851461f60            opc drum  inorganic photoconductor drum   \n",
              "1  09e418c93a776564     adjust gas flow              altering gas flow   \n",
              "2  36baf228038e314b      lower trunnion                 lower locating   \n",
              "3  1f37ead645e7f0c8       cap component                  upper portion   \n",
              "4  71a5b6ad068d531f  neural stimulation      artificial neural network   \n",
              "\n",
              "  context                                              title sep_token  \\\n",
              "0     G02                                             optics     [SEP]   \n",
              "1     F23          combustion apparatus combustion processes     [SEP]   \n",
              "2     B60                                vehicles in general     [SEP]   \n",
              "3     D06  treatment of textiles or the like laundering f...     [SEP]   \n",
              "4     H04                   electric communication technique     [SEP]   \n",
              "\n",
              "  cls_token context_token                                               text  \n",
              "0     [CLS]         [G02]                                    optics opc drum  \n",
              "1     [CLS]         [F23]  combustion apparatus combustion processes adju...  \n",
              "2     [CLS]         [B60]                 vehicles in general lower trunnion  \n",
              "3     [CLS]         [D06]  treatment of textiles or the like laundering f...  \n",
              "4     [CLS]         [H04]  electric communication technique neural stimul...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7220bd3-5758-4b17-a00f-c45f5c9ddf9a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "      <th>title</th>\n",
              "      <th>sep_token</th>\n",
              "      <th>cls_token</th>\n",
              "      <th>context_token</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4112d61851461f60</td>\n",
              "      <td>opc drum</td>\n",
              "      <td>inorganic photoconductor drum</td>\n",
              "      <td>G02</td>\n",
              "      <td>optics</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[G02]</td>\n",
              "      <td>optics opc drum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>09e418c93a776564</td>\n",
              "      <td>adjust gas flow</td>\n",
              "      <td>altering gas flow</td>\n",
              "      <td>F23</td>\n",
              "      <td>combustion apparatus combustion processes</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[F23]</td>\n",
              "      <td>combustion apparatus combustion processes adju...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36baf228038e314b</td>\n",
              "      <td>lower trunnion</td>\n",
              "      <td>lower locating</td>\n",
              "      <td>B60</td>\n",
              "      <td>vehicles in general</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[B60]</td>\n",
              "      <td>vehicles in general lower trunnion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1f37ead645e7f0c8</td>\n",
              "      <td>cap component</td>\n",
              "      <td>upper portion</td>\n",
              "      <td>D06</td>\n",
              "      <td>treatment of textiles or the like laundering f...</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[D06]</td>\n",
              "      <td>treatment of textiles or the like laundering f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71a5b6ad068d531f</td>\n",
              "      <td>neural stimulation</td>\n",
              "      <td>artificial neural network</td>\n",
              "      <td>H04</td>\n",
              "      <td>electric communication technique</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[H04]</td>\n",
              "      <td>electric communication technique neural stimul...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7220bd3-5758-4b17-a00f-c45f5c9ddf9a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7220bd3-5758-4b17-a00f-c45f5c9ddf9a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7220bd3-5758-4b17-a00f-c45f5c9ddf9a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xsTf2Rz2H0Iw"
      },
      "outputs": [],
      "source": [
        "encoded_test_data = encode_text(test_data[[\"text\", \"target\"]].values.tolist(), tokenizer, Config.max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQTzqbhYH0Ix",
        "outputId": "99db17e6-d0ce-4350-802d-4e85f41c563e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    2 20691  6393  1943  6608     3 27921  5967  8328  8231 16426  6608\n",
            "     3     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "print(encoded_test_data[\"input_ids\"][0])\n",
        "print(encoded_test_data[\"attention_masks\"][0])\n",
        "print(encoded_test_data[\"token_type_ids\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r-wc3zXH0Iy",
        "outputId": "99034ad1-a12a-4398-89d3-baf92098d984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test x shape :  (36, 96) (36, 96) (36, 96)\n"
          ]
        }
      ],
      "source": [
        "test_x = [encoded_test_data[\"input_ids\"], encoded_test_data[\"attention_masks\"], encoded_test_data[\"token_type_ids\"]]\n",
        "print(\"test x shape : \", test_x[0].shape, test_x[1].shape, test_x[2].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YT4G5KDYH0Iy"
      },
      "outputs": [],
      "source": [
        "def build_model(config):\n",
        "    # Create the model under a distribution strategy scope.\n",
        "    with strategy.scope():\n",
        "        # Encoded token ids from BERT tokenizer.\n",
        "        input_ids = tf.keras.layers.Input(\n",
        "            shape=(config.max_length,), dtype=tf.int32, name=\"input_ids\"\n",
        "        )\n",
        "        # Attention masks indicates to the model which tokens should be attended to.\n",
        "        attention_masks = tf.keras.layers.Input(\n",
        "            shape=(config.max_length,), dtype=tf.int32, name=\"attention_masks\"\n",
        "        )\n",
        "        # Token type ids are binary masks identifying different sequences in the model.\n",
        "        token_type_ids = tf.keras.layers.Input(\n",
        "            shape=(config.max_length,), dtype=tf.int32, name=\"token_type_ids\"\n",
        "        )\n",
        "        # Loading pretrained BERT model.\n",
        "        base_model = transformers.TFAutoModel.from_pretrained(config.base_model, from_pt=True)\n",
        "\n",
        "        base_model_output = base_model(\n",
        "            input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        last_hidden_state = base_model_output.last_hidden_state\n",
        "        avg_pool = tf.keras.layers.GlobalAveragePooling1D()(last_hidden_state)\n",
        "        dropout = tf.keras.layers.Dropout(0.3)(avg_pool)\n",
        "\n",
        "        output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(dropout)\n",
        "\n",
        "        model = tf.keras.models.Model(\n",
        "            inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n",
        "        )\n",
        "\n",
        "        model.compile(\n",
        "            optimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate),\n",
        "            loss=tf.keras.losses.BinaryCrossentropy()\n",
        "        )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics for Competition"
      ],
      "metadata": {
        "id": "XZ0NPrmRL81F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Pearsonr(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, val_data, y_val):\n",
        "        self.val_data = val_data\n",
        "        self.y_val = y_val\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        val_preds = self.model.predict(self.val_data, verbose=0)\n",
        "        \n",
        "        val_pearsonr = stats.pearsonr(self.y_val, val_preds.ravel())[0]\n",
        "\n",
        "        print(f\"val_pearsonr: {val_pearsonr:.4f}\\n\")\n",
        "        logs[\"val_pearsonr\"] = val_pearsonr"
      ],
      "metadata": {
        "id": "RNrp-cBsL8EJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model K Fold Training\n",
        "Use previously trained weight first"
      ],
      "metadata": {
        "id": "gymdq4e1Kury"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_folds(train, config):\n",
        "    oof = np.zeros(len(train))\n",
        "    pretrained_model_loaded = False\n",
        "    train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n",
        "    \n",
        "    skf = StratifiedKFold(n_splits=config.num_folds, \n",
        "                      shuffle=True,\n",
        "                      random_state=config.seed)\n",
        "    \n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(train, train['score_map'])):\n",
        "        print(\"*\" * 50)\n",
        "        print(f\"Training fold: {fold+1}\")\n",
        "\n",
        "        train_df = train.loc[train_idx].reset_index(drop=True)\n",
        "        # print(train_df.head(2))\n",
        "        val_df = train.loc[val_idx].reset_index(drop=True)\n",
        "        \n",
        "        # Clear keras session.\n",
        "        K.clear_session()\n",
        "        \n",
        "        train_encoded =  encode_text(train_df[\"text\"].tolist(),\n",
        "                                     tokenizer=tokenizer,\n",
        "                                     max_length=config.max_length)\n",
        "        \n",
        "        val_encoded =  encode_text(val_df[\"text\"].tolist(),\n",
        "                                     tokenizer=tokenizer,\n",
        "                                     max_length=config.max_length)\n",
        "        # Dataloader.\n",
        "        train_data = tf.data.Dataset.from_tensor_slices((train_encoded, train_df['score'].tolist()))\n",
        "        val_data = tf.data.Dataset.from_tensor_slices((val_encoded, val_df['score'].tolist()))\n",
        "\n",
        "        train_data = (\n",
        "                        train_data\n",
        "                        .shuffle(1024)\n",
        "                        .batch(config.batch_size)\n",
        "                        .prefetch(tf.data.AUTOTUNE)\n",
        "                     )\n",
        "        \n",
        "        val_data = (\n",
        "                        val_data\n",
        "                        .batch(config.batch_size)\n",
        "                        .prefetch(tf.data.AUTOTUNE)\n",
        "                    )\n",
        "\n",
        "        # Callbacks.\n",
        "        checkpoint = tf.keras.callbacks.ModelCheckpoint(f'model-{fold+1}.h5',\n",
        "                                                        monitor='val_loss',\n",
        "                                                        mode='min',\n",
        "                                                        save_best_only=True,\n",
        "                                                        save_weights_only=True,\n",
        "                                                        save_freq='epoch',\n",
        "                                                        verbose=1)\n",
        "        \n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                          mode='min',\n",
        "                                                          patience=3,\n",
        "                                                          verbose=1)\n",
        "        \n",
        "        pearsonr_callback = Pearsonr(val_data, val_df['score'].values)\n",
        "        num_train_steps = int(len(train_df) / config.batch_size * config.epochs)\n",
        "        \n",
        "        # Build and Train model.\n",
        "        model = build_model(config) #, num_train_steps\n",
        "        # for the first time in Colab load the pretrained model\n",
        "        if pretrained_model_loaded == False:\n",
        "          #model.load_weights(TRAINED_MODEL_PATH)\n",
        "          pretrained_model_loaded = True\n",
        "          print(\"Our own pretrained model loaded......\")\n",
        "        history = model.fit(\n",
        "                        train_data,\n",
        "                        validation_data=val_data,\n",
        "                        epochs=config.epochs,\n",
        "                        callbacks=[checkpoint, \n",
        "                                   early_stopping, \n",
        "                                   pearsonr_callback],\n",
        "                        verbose=1\n",
        "                    )\n",
        "        \n",
        "        print('\\nLoading best model weights...')\n",
        "        model.load_weights(f'model-{fold+1}.h5')\n",
        "        \n",
        "        print('Predicting OOF...')\n",
        "        oof[val_idx] = model.predict(val_data,\n",
        "                                     batch_size=config.batch_size,\n",
        "                                     verbose=0).reshape(-1)\n",
        "        \n",
        "        \n",
        "        score = stats.pearsonr(val_df['score'].values, oof[val_idx])[0]\n",
        "        print(f'\\nFold {fold + 1}: OOF pearson_r: {score:.4f}')        \n",
        "        print(\"*\" * 25)\n",
        "        \n",
        "    score = stats.pearsonr(train['score'].values, oof)[0]\n",
        "    print(f'\\nOverall OOF pearson_r: {score:.4f}')\n",
        "    return oof"
      ],
      "metadata": {
        "id": "BculjIqkK0cU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8nh8nzyiH0Iz",
        "outputId": "9923c2dd-7245-4b01-fa87-0e848c4d28a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************\n",
            "Training fold: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.embeddings.position_ids', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our own pretrained model loaded......\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-419bc4c32475>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moof_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-7a14b38440ce>\u001b[0m in \u001b[0;36mtrain_folds\u001b[0;34m(train, config)\u001b[0m\n\u001b[1;32m     74\u001b[0m                                    \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                                    pearsonr_callback],\n\u001b[0;32m---> 76\u001b[0;31m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                     )\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nOut of memory while trying to allocate 16777216 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:   50.03MiB\n              constant allocation:        56B\n        maybe_live_out allocation:  170.02MiB\n     preallocated temp allocation:       216B\n                 total allocation:  188.04MiB\n              total fragmentation:       296B (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 24.00MiB\n\t\tOperator: op_type=\"Reshape\" op_name=\"model/tf_bert_model/bert/encoder/layer_._7/output/dense/Tensordot/Reshape\"\n\t\tXLA Label: fusion\n\t\tShape: f32[1536,4096]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 24.00MiB\n\t\tOperator: op_type=\"AddV2\" op_name=\"model/tf_bert_model/bert/encoder/layer_._7/intermediate/Gelu/add\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,4096]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 24.00MiB\n\t\tOperator: op_type=\"AddV2\" op_name=\"model/tf_bert_model/bert/encoder/layer_._7/intermediate/Gelu/add\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,4096]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 24.00MiB\n\t\tOperator: op_type=\"AddV2\" op_name=\"model/tf_bert_model/bert/encoder/layer_._7/intermediate/Gelu/add\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,4096]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 16.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tEntry Parameter Subshape: f32[4096,1024]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 16.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tEntry Parameter Subshape: f32[1024,4096]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 6.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tEntry Parameter Subshape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 6.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tEntry Parameter Subshape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 6.00MiB\n\t\tXLA Label: copy\n\t\tShape: f32[1536,1024]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 6.00MiB\n\t\tOperator: op_type=\"BiasAdd\" op_name=\"model/tf_bert_model/bert/encoder/layer_._7/output/dense/BiasAdd\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 6.00MiB\n\t\tOperator: op_type=\"AddV2\" op_name=\"model/tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/batchnorm/add_1\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 6.00MiB\n\t\tOperator: op_type=\"AddV2\" op_name=\"model/tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/batchnorm/add_1\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 6.00MiB\n\t\tOperator: op_type=\"Mean\" op_name=\"model/tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/moments/variance\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 6.00MiB\n\t\tOperator: op_type=\"Mean\" op_name=\"model/tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/moments/mean\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,1024]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 6.00MiB\n\t\tOperator: op_type=\"Mean\" op_name=\"model/tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/moments/mean\"\n\t\tXLA Label: fusion\n\t\tShape: f32[16,96,1024]\n\t\t==========================\n\n\n\t [[{{node cluster_227_1/xla_run}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_160270]"
          ]
        }
      ],
      "source": [
        "config = Config()\n",
        "oof_preds = train_folds(train_data, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KdR2RYLH0Iz"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "model.load_weights('model-2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWa4C0IxH0I0"
      },
      "outputs": [],
      "source": [
        "# Lets predict the test data.\n",
        "predictions = model.predict(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38Q0Pv_QH0I0"
      },
      "outputs": [],
      "source": [
        "# Lets read sample submission file.\n",
        "submission = pd.read_csv('sample_submission.csv')\n",
        "submission['score'] = predictions\n",
        "submission['score'] = submission.score.apply(lambda x: 0 if x < 0 else x)\n",
        "submission['score'] = submission.score.apply(lambda x: 1 if x > 1 else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19WKauexH0I1",
        "outputId": "1f5e4d8c-7544-4eb5-d550-bac3863449eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4112d61851461f60</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>09e418c93a776564</td>\n",
              "      <td>0.363816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36baf228038e314b</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1f37ead645e7f0c8</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71a5b6ad068d531f</td>\n",
              "      <td>0.363816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>474c874d0c07bd21</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>442c114ed5c4e3c9</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>b8ae62ea5e1d8bdb</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>faaddaf8fcba8a3f</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ae0262c02566d2ce</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>a8808e31641e856d</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>16ae4b99d3601e60</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>25c555ca3d5a2092</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>5203a36c501f1b7c</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>b9fdc772bb8fd61c</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7aa5908a77a7ec24</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>d19ef3979396d47e</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>fd83613b7843f5e1</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2a619016908bfa45</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>733979d75f59770d</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>6546846df17f9800</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3ff0e7a35015be69</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>12ca31f018a2e2b9</td>\n",
              "      <td>0.363816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>03ba802ed4029e4d</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>c404f8b378cbb008</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>78243984c02a72e4</td>\n",
              "      <td>0.363813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>de51114bc0faec3e</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>7e3aff857f056bf9</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>26c3c6dc6174b589</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>b892011ab2e2cabc</td>\n",
              "      <td>0.363816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>8247ff562ca185cc</td>\n",
              "      <td>0.363814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>c057aecbba832387</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>9f2279ce667b21dc</td>\n",
              "      <td>0.363816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>b9ea2b06a878df6f</td>\n",
              "      <td>0.363816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>79795133c30ef097</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>25522ee5411e63e9</td>\n",
              "      <td>0.363815</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id     score\n",
              "0   4112d61851461f60  0.363815\n",
              "1   09e418c93a776564  0.363816\n",
              "2   36baf228038e314b  0.363814\n",
              "3   1f37ead645e7f0c8  0.363814\n",
              "4   71a5b6ad068d531f  0.363816\n",
              "5   474c874d0c07bd21  0.363815\n",
              "6   442c114ed5c4e3c9  0.363815\n",
              "7   b8ae62ea5e1d8bdb  0.363815\n",
              "8   faaddaf8fcba8a3f  0.363815\n",
              "9   ae0262c02566d2ce  0.363815\n",
              "10  a8808e31641e856d  0.363815\n",
              "11  16ae4b99d3601e60  0.363815\n",
              "12  25c555ca3d5a2092  0.363815\n",
              "13  5203a36c501f1b7c  0.363815\n",
              "14  b9fdc772bb8fd61c  0.363815\n",
              "15  7aa5908a77a7ec24  0.363815\n",
              "16  d19ef3979396d47e  0.363815\n",
              "17  fd83613b7843f5e1  0.363814\n",
              "18  2a619016908bfa45  0.363815\n",
              "19  733979d75f59770d  0.363815\n",
              "20  6546846df17f9800  0.363815\n",
              "21  3ff0e7a35015be69  0.363814\n",
              "22  12ca31f018a2e2b9  0.363816\n",
              "23  03ba802ed4029e4d  0.363814\n",
              "24  c404f8b378cbb008  0.363815\n",
              "25  78243984c02a72e4  0.363813\n",
              "26  de51114bc0faec3e  0.363815\n",
              "27  7e3aff857f056bf9  0.363814\n",
              "28  26c3c6dc6174b589  0.363814\n",
              "29  b892011ab2e2cabc  0.363816\n",
              "30  8247ff562ca185cc  0.363814\n",
              "31  c057aecbba832387  0.363815\n",
              "32  9f2279ce667b21dc  0.363816\n",
              "33  b9ea2b06a878df6f  0.363816\n",
              "34  79795133c30ef097  0.363815\n",
              "35  25522ee5411e63e9  0.363815"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission.to_csv(\"submission.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz6zmOZtH0I1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "24ffb122db4d293cbce3a5b97151e6069f3c74d2302b3d157e23222a76757a60"
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 ('kaggle-nlp')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "colab-training-v2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}